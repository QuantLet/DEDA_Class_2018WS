{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\justin\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\justin\\anaconda3\\lib\\site-packages (3.13)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\justin\\anaconda3\\lib\\site-packages (from h5py) (1.16.1)\n",
      "Requirement already satisfied: six in c:\\users\\justin\\anaconda3\\lib\\site-packages (from h5py) (1.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow' \n",
    "!pip install h5py pyyaml \n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, CuDNNLSTM\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.optimizers import RMSprop\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script will first run the Markov Chain and then the LSTM model to generate Donald Trump tweets.\n",
      "Run the Jupyter notebook if you want to use just one or the other \n",
      "- or if you wannt to play around with state length/seed text/temperature etc.\n",
      "The training part is commented out to prevent you from accidentally running it. It will take hours per epoch on a CPU, so make sure you run it on a powerful GPU. If your GPU is tensorflow compatible, use CuDNNLSTM instead of LSTM.\n"
     ]
    }
   ],
   "source": [
    "print('This script will first run the Markov Chain and then the LSTM model to generate Donald Trump tweets.\\nRun the Jupyter notebook if you want to use just one or the other \\n- or if you wannt to play around with state length/seed text/temperature etc.\\nThe training part is commented out to prevent you from accidentally running it. It will take hours per epoch on a weak CPU, so make sure you run it on a powerful GPU. If your GPU is tensorflow compatible, use CuDNNLSTM instead of LSTM.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4290385\n",
      "total unique chars: 92 \n",
      "characters:\n",
      " ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
      "sequences: 536286\n",
      "Vectorization... \n",
      "This can take a moment.\n",
      "Done.\n",
      "Ready to generate text and further train the model.\n"
     ]
    }
   ],
   "source": [
    "## import and prepare text\n",
    "# Import Text > can be replaced with your own text, but then you need to train the model from scratch.\n",
    "file= open('TRUMPTWEETS.txt',  encoding=\"utf8\") #taken from http://www.trumptwitterarchive.com/\n",
    "text = file.read()\n",
    "file.close()\n",
    "print(len(text))\n",
    "rawtxt=text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "text=text[:2145192] #drop half the text to speed up everything.\n",
    "\n",
    "\n",
    "# adapted from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py - as are some helperfunctions later on\n",
    "# Create a list of Chars\n",
    "chars = sorted(list(set(text[:2145192])))\n",
    "print('total unique chars:', len(chars),'\\ncharacters:\\n', chars)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 50\n",
    "step = 4\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('sequences:', len(sentences))\n",
    "\n",
    "#vectorise\n",
    "print('Vectorization... \\nThis can take a moment.')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print('Done.\\nReady to generate text and further train the model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MARKOV CHAIN\n",
      "\n",
      "Creating the model with state length = {}.\n",
      "You can edit STATE_LEN in the script.\n",
      " lower numbers yield more creative but messy results, higher numbers yield cleaner results but mostly reguritate the training data.\n",
      "Learning model...\n",
      "Done.\n",
      "Starting state: \"Crook\"\n",
      "Crooked Hillary Citizens of very open to built inter show with the middle Easter Bad just like watch.,01-23-2013 23:06,22,16,false,29417000960\n",
      "Twitter Web Client,@jameshohmann  Thanks for president\"|@DrewMiller728     \"@realDonaldTrump Your A.G. Eric Schn \n",
      "\n",
      "Starting state: \"Fake \"\n",
      "Fake New York Time Ministration my records. These changes you in New York Jets show trying to fix the United Saturdays on Monday http://t.co/UnboWqeX86|I am now they will be able no players.|@tazracet of Alabama!|Cutting torn up. Man officialBQGirls (wome \n",
      "\n",
      "Starting state: \"China\"\n",
      "China returned for Android,@iNathalieS_29 Nathanmportant job! A wonderful play golf fantastic--these back with debates by @SethMcLaughlinGroup donors tomorrows electionNightJimmy.|@BarackObamas like that the public Contract Ebola traine today night me a d \n",
      "\n",
      "Starting state: \"Rober\"\n",
      "Robertfritz: @realDonaldTrump @thehill in U.S. FINDS IN NEWS... http://t.co/YRcqKNbG|Congrats! Excellent of Collection much the sector Jackson for Presential rating even more it against U.S. will saved by Rene Liberty and total global was an expect for jo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Markov chain\n",
    "#'Training'\n",
    "#taken from:\n",
    "#https://eli.thegreenplace.net/2018/elegant-python-code-for-a-markov-chain-text-generator/\n",
    "STATE_LEN = 5\n",
    "print('\\nMARKOV CHAIN\\n\\nCreating the model with state length = {}.\\nYou can edit STATE_LEN in the script.\\n lower numbers yield more creative but messy results, higher numbers yield cleaner results but mostly reguritate the training data.')\n",
    "\n",
    "data = rawtxt\n",
    "model = defaultdict(Counter)\n",
    "\n",
    "print('Learning model...')\n",
    "for i in range(len(data) - STATE_LEN):\n",
    "    state = data[i:i + STATE_LEN]\n",
    "    next = data[i + STATE_LEN]\n",
    "    model[state][next] += 1\n",
    "print('Done.')\n",
    "\n",
    "#  generation\n",
    "statelist = ['Crooked Hillary', 'Fake News', 'China ', 'Robert Muller', 'We'] # you can add your own see text here.\n",
    "for state in statelist:\n",
    "    if len(state)>=STATE_LEN:\n",
    "        state=state[:STATE_LEN]\n",
    "        print('Starting state: \"{}\"'.format(state))\n",
    "        out = list(state)\n",
    "        for i in range(250):\n",
    "            out.extend(random.choices(list(model[state]), model[state].values()))\n",
    "            state = state[1:] + out[-1]\n",
    "        print(''.join(out),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LSTM\n",
      "Building LSTM model...\n",
      "Compiling ...\n",
      "Done!\n",
      "Weights loaded.\n"
     ]
    }
   ],
   "source": [
    "# build the model: a two-layer LSTM\n",
    "print('\\n\\nLSTM\\nBuilding LSTM model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(250,return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(LSTM(250))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "optimizer = RMSprop(lr=0.005)\n",
    "print('Compiling ...')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print('Done!')\n",
    "#load weights\n",
    "model.load_weights('TRUMPWEIGHTS.hdf5')\n",
    "print('Weights loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds+0.000000000000001) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def gen_text():\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.008,0.2, 0.3, 0.4, 0.5, 1.0, 1.2]:\n",
    "        print('\\n----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(300):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generation with a random starter seed:\n",
      "\n",
      "\n",
      "----- diversity: 0.008\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've came to the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've come to the U.S. is a great job on @FoxNews and the U.S. is a great job on @FoxNews and the Democrats are so much more than any other country with the best of the people of the U.S. is a great president of the United States of the United States with the U.S. is a great deal of the U.S. is a great sup\n",
      "----- diversity: 0.3\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've come to the U.S. the deal in the next president of the United States of the United States with the bad that China will be the best and statement from the U.S. is a great complete and the people are with the many of the best families and the people are all time to the border of the United States with \n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've constantly been going to read that the real building is a great job on @FoxNews and the Democrats should be a disaster. We need a big prices are making a deal on @FoxNews and @CNN has been a great job on @FoxNews in the support of the ballot. So true!|@JoshFartherlars: @realDonaldTrump @realDonaldTru\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've came to the U.S. has not be such a really deal since the truth. Thank you!|@mike__arrop2: @realDonaldTrump The Republicans are happy and thanks.|@camerson: @realDonaldTrump We are not began for the @WhiteHouse. They were happening to stop asking to be strong on China. Played the best than the White H\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've constantly running him! Championships and money.!  \"The only minest is just some of the wordi (ball of borders|@nbc  You are NEVER &amp; replace to Oifice. Democrats out of this man in New York Times PolozipEThe Roop' created from major but @BarackObama will do some of the story @realDonaldTrump .Wha\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"roblem!|@Woodsy_gal: Been a long time since I've c\"\n",
      "roblem!|@Woodsy_gal: Been a long time since I've close the opportunity. China nike u desperate andaposs by Tenay\"|@rack:  Thanks--I think interview when will hime Beini and Jerry Oslosi on U.N.??? That's government! @realDonaldTrump so surphum! #CelebApprentice @aberdeenInForcon Focur: Call @GolfDorkin  watch WI) a wonderful penchess to OUT!,09-18-\n",
      "\n",
      "Text generation with another random starter:\n",
      "\n",
      "----- diversity: 0.008\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump and @realDonaldTrump http://t.co/JJZZXZJZ|@MittRomney is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump on @FoxNews in the world and the most experience of the U.S. has been a great country and a big progress and the most experience of the U.S. is a total disaster of the politicians and the man who has been sure to be the best thing when I am surprised the president of the United States with the \n",
      "----- diversity: 0.3\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump on @FoxNews at 7:00 A.M. Enjoy!|@MarkStephen @realDonaldTrump @realDonaldTrump @ApprenticeNBC @realDonaldTrump http://t.co/XZJ7rJKSfT|@BarackObama has a great company than any other country that would be coming to the U.S. is so long and so much more than the world would be a great president. T\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump and @realDonaldTrump would be an exceptional show on the country to be great!|Great job on @foxandfriends at 7:30. And needs you!|@joadlassell                                                                                                                      \"@realDonaldTrump @ApprenticeNBC  I\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump http://t.co/yYZ1bwx LYOBS TRUMP IN THE CAN IN ON ON AND FAL! THE UN THE YOU SUGE AMERICA TRUMP WHAT YOU HERS IN BEAT LISE -- Donald Trump will see you and such a strong beginning of the saturday to work in the debate. Stop the POTUS. But they are really bad of better than the Republican Party C\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump  Thank you!|@JustyHistoroges: After I bot Mary of The Art of the Deal|@VettayBo_Byner: @realDonaldTrump is hurting why I looking forward to singly ack. Trade signation to NYC. Super Help Sadly. - &amp; Summit Rick about old representatives to the great East hates! @JebBush as I hope the best se\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" The only winner of the #DemDebate is @realDonaldT\"\n",
      " The only winner of the #DemDebate is @realDonaldTrump she put for his bright.|New Andreid &amp; COUSTIDA or de chances. That mess the Dodting today!|Just set up Taking Man'cool.|.@jakefarner: They arelingled I'll do our trade. Expoging the no live at @realDonaldTrump and DONALD RE!|Bush after joy roads &amp; city to make dropped|The solution is wi\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Text generation with a random starter seed:\\n')\n",
    "gen_text()\n",
    "print('\\nText generation with another random starter:')\n",
    "gen_text()\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights of another model. This model has been trained a bit longer and on a bit more of the data.\n",
      "Done.\n",
      "Text generation with a random starter seed:\n",
      "\n",
      "\n",
      "----- diversity: 0.008\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It is a great president of the U.S. is a great place. We are not watching the problem in the U.S. is a great president of the U.S. is a great job on @FoxNews and the Democrats that the U.S. is a true and work on the same time to be a big deal on the support of the United States of the U.S. in the worl\n",
      "----- diversity: 0.3\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It is a big change in the world with a great course to the U.S. to the money for the best time with @BarackObama like a great job on @FoxNews in the U.S. is a lot of trade deal with the presidential interview with @realDonaldTrump when the truth is a major people of the U.S. is looking for the most bo\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It is the people are looking forward to being in the plane last night. Thank you!|@seanhannity: @realDonaldTrump I am so looking forward to it!|We are the best person at the @WhiteHouse is a lot of comments who is really fighting to see the and speaking and makes a disgrace to the U.S. and Sandy Poll \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It was a big day and some of the man for the same top problems and all of the fact that I believe that the @GOP and the real protestion is better to save the horrible people and fact of the GREAT of the most accessful and never show that many people are going to bring him with people fighting and indu\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It was true is an incredible Patriot @exanner|Thank you The Golf Kelly. We are always to smart the resouncemant on Manupoll of the Boast and over Law Secretary of Say Lincoln|Why shouldn't a strength this. #SimpohnShamberman Thanks!|@Corriflow: @realDonaldTrump always some of my press and get the brig\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"mitment it has made to the U.S. and its allies. It\"\n",
      "mitment it has made to the U.S. and its allies. It is still willlings fires crooked.|I'll be funhard man that this will Lose Polls in Crooked Hillary come the wis America are the work hard.|@luary6Mcvorm: A NATO will stop opening!|@N@CRO I send good- thanks.  You and everything police is nowhing for the wiase|@ Eric https://t.co/|koq4vCi34|@Jenniuc\n",
      "\n",
      "Text generation with another random starter:\n",
      "\n",
      "----- diversity: 0.008\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S. is a great president of the U.S.\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump is a great job on @FoxNews at 7:00 A.M. @realDonaldTrump @TrumpScotland @CNN @realDonaldTrump @realDonaldTrump http://t.co/59nu54JT|@Josh_Really @realDonaldTrump @realDonaldTrump @realDonaldTrump @TrumpTowerNY @realDonaldTrump  Thanks.|@RonNews @TheBrooks https://t.co/XHHjkFbiyh|I will be interv\n",
      "----- diversity: 0.3\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump is a great job on @FoxNews and the all the bad increase to the world with @realDonaldTrump http://t.co/09m0BXKElF|@dama_girl: @realDonaldTrump @realDonaldTrump I will be there when the most of the world will be a great time in the world and so much to fix the best for the presidential collusion \n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump will be great!|@Benavid_Mobber: @realDonaldTrump @realDonaldTrump @Macys Thank you!|@caller_ander: @realDonaldTrump @DanScavino @realDonaldTrump @realDonaldTrump was the first place!|@TheBrookson4: @realDonaldTrump you have a president who has been stronged the fact that the story is not seem th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump can't be the best amazing last night in New Hampshire and sell the good political course to welcome the Republicans and the world and the best time to the DONALD TRUMP!|@GolfDigrader: @realDonaldTrump @DannyZuker @realDonaldTrump @realDonaldTrump #Trump2016 https://t.co/1tKI2IfnBq|@EricTrump @re\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump's Bernie Man is CLN-Continue to China for his making of the high. I have failing win and we have the truth first famous Iith  Look for an apologizing for the great members and signations|@JohnChirsaTeds  @MasterlailJohnmith bujpving @OMAROSA Signature now in Scotland tool up by restaurant overti\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rting the big jobs push back into the U.S.!|How Tr\"\n",
      "rting the big jobs push back into the U.S.!|How Trump will run? Thank you! #IndazinRUNB   Most bad account/heed he lie you love &amp; pock-sites. Mayor to prohle NAKO NELERETER and the man can makes!|@RealDan_OPhang  USeas restrocksham.)|Well--there were treated buo stuffh like the Trump International Washington DS|@MaryGoog:   Thank you!|@OCial_co\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Loading weights of another model. This model has been trained a bit longer and on a bit more of the data.')\n",
    "model.load_weights('TRUMPWEIGHTS_more_training.hdf5')\n",
    "print('Done.\\nText generation with a random starter seed:\\n')\n",
    "gen_text()\n",
    "print('\\nText generation with another random starter:')\n",
    "gen_text()\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training would start here. Uncomment the code to train it further.\n"
     ]
    }
   ],
   "source": [
    "# define print out call back\n",
    "def on_epoch_end(epoch, _):\n",
    "    if epoch == 1 or epoch%2==0:\n",
    "            # Function invoked at end of each epoch. Prints generated text.\n",
    "            print()\n",
    "            print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "            start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "            for diversity in [0.1, 0.5, 1.0, 1.4]:\n",
    "                print('----- diversity:', diversity)\n",
    "                generated = ''\n",
    "                sentence = text[start_index: start_index + maxlen]\n",
    "                #sentence = starter_seq[:]\n",
    "                generated += sentence\n",
    "                print('----- Generating with seed: \"' + sentence + '\"-----')\n",
    "                sys.stdout.write(generated)\n",
    "\n",
    "                for i in range(1400):\n",
    "                    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                    for t, char in enumerate(sentence):\n",
    "                        x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                    preds = model.predict(x_pred, verbose=0)[0]\n",
    "                    next_index = sample(preds, diversity)\n",
    "                    next_char = indices_char[next_index]\n",
    "\n",
    "                    generated += next_char\n",
    "                    sentence = sentence[1:] + next_char\n",
    "\n",
    "                    sys.stdout.write(next_char)\n",
    "                    sys.stdout.flush()\n",
    "                print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "print('Model training would start here. Uncomment the code to train it further.')\n",
    "# train model some more\n",
    "## if you're not a GPU, this will take a very, very long time\n",
    "# model.fit(x, y,\n",
    "#           batch_size=1024,\n",
    "#           epochs=10,\n",
    "#           verbose=1,\n",
    "#           callbacks=[print_callback,tf.keras.callbacks.ModelCheckpoint('{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', period=2)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
